#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”Ÿæˆ108ç§è®¤çŸ¥æ­¦å™¨çš„æ•°æ®æ–‡ä»¶
ä»HTMLæ–‡ä»¶ä¸­æå–æ ‡é¢˜å’Œæè¿°ï¼Œç”ŸæˆJSONæ•°æ®
"""

import os
import json
import re
from html.parser import HTMLParser

class TitleExtractor(HTMLParser):
    """æå–HTMLä¸­çš„titleæ ‡ç­¾å†…å®¹"""
    def __init__(self):
        super().__init__()
        self.in_title = False
        self.title = ""

    def handle_starttag(self, tag, attrs):
        if tag == "title":
            self.in_title = True

    def handle_endtag(self, tag):
        if tag == "title":
            self.in_title = False

    def handle_data(self, data):
        if self.in_title:
            self.title += data

def extract_title_from_html(file_path):
    """ä»HTMLæ–‡ä»¶ä¸­æå–æ ‡é¢˜"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            parser = TitleExtractor()
            parser.feed(content)
            return parser.title.strip()
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
        return None

def extract_title_from_js_config(file_path):
    """ä»JavaScripté…ç½®ä¸­æå–ä¸­æ–‡å’Œè‹±æ–‡æ ‡é¢˜ï¼ˆç”¨äº017åŠä¹‹åçš„æ–‡ä»¶ï¼‰"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

            # æå–ä¸­æ–‡æ ‡é¢˜ï¼šzh: { header: { title: "xxx"
            zh_match = re.search(r'zh:\s*{[^}]*header:\s*{[^}]*title:\s*["\']([^"\']+)["\']', content, re.DOTALL)
            zh_title = zh_match.group(1) if zh_match else None

            # æå–è‹±æ–‡æ ‡é¢˜ï¼šen: { header: { title: "xxx"
            en_match = re.search(r'en:\s*{[^}]*header:\s*{[^}]*title:\s*["\']([^"\']+)["\']', content, re.DOTALL)
            en_title = en_match.group(1) if en_match else None

            return zh_title, en_title
    except Exception as e:
        print(f"Error extracting JS config from {file_path}: {e}")
        return None, None

def parse_filename(filename):
    """ä»æ–‡ä»¶åè§£æåºå·å’Œè‹±æ–‡æ ‡é¢˜"""
    # æ ¼å¼: 001_The Learning Pyramid.html
    match = re.match(r'(\d+)_(.+)\.html', filename)
    if match:
        number = match.group(1)
        en_title = match.group(2)
        return number, en_title
    return None, None

def generate_cognitive_weapons_data():
    """ç”Ÿæˆè®¤çŸ¥æ­¦å™¨æ•°æ®"""
    projects_dir = "projects/108 Cognitive Weapons"
    data = []

    # è·å–æ‰€æœ‰HTMLæ–‡ä»¶
    files = [f for f in os.listdir(projects_dir) if f.endswith('.html')]
    files.sort()  # æŒ‰æ–‡ä»¶åæ’åº

    for filename in files:
        number, en_title_from_filename = parse_filename(filename)
        if not number:
            continue

        file_path = os.path.join(projects_dir, filename)

        # å°è¯•ä»JavaScripté…ç½®ä¸­æå–æ ‡é¢˜ï¼ˆç”¨äº017åŠä¹‹åçš„æ–‡ä»¶ï¼‰
        js_zh_title, js_en_title = extract_title_from_js_config(file_path)

        # å¦‚æœJSé…ç½®ä¸­æœ‰æ ‡é¢˜ï¼Œä¼˜å…ˆä½¿ç”¨
        if js_zh_title and js_en_title:
            cn_title = js_zh_title
            en_title = js_en_title
            description = f"{en_title} - {cn_title}"
            print(f"  {number}: {cn_title} ({en_title}) [ä»JSé…ç½®æå–]")
        else:
            # å¦åˆ™ä»HTML titleæ ‡ç­¾æå–ï¼ˆé€‚ç”¨äº001-016ï¼‰
            full_title = extract_title_from_html(file_path)
            cn_title = en_title_from_filename  # é»˜è®¤ä½¿ç”¨æ–‡ä»¶åä¸­çš„è‹±æ–‡æ ‡é¢˜
            en_title = en_title_from_filename
            description = en_title_from_filename

            if full_title and full_title != "è®¤çŸ¥æ¨¡å‹å·¥å‚ - Cognitive Model Generator":
                # å°è¯•æå–ä¸­æ–‡æ ‡é¢˜ï¼ˆç¬¬ä¸€ä¸ª - ä¹‹å‰çš„éƒ¨åˆ†ï¼‰
                # æ ¼å¼: "ä¸­æ–‡æ ‡é¢˜ - 108ç§è®¤çŸ¥æ­¦å™¨ | English Title - 108 Cognitive Weapons"
                parts = full_title.split('-')
                if len(parts) > 0:
                    cn_part = parts[0].strip()
                    # å¦‚æœåŒ…å«ä¸­æ–‡å­—ç¬¦ï¼Œä½¿ç”¨å®ƒ
                    if any('\u4e00' <= c <= '\u9fff' for c in cn_part):
                        cn_title = cn_part

                # å°è¯•æå–è‹±æ–‡æ ‡é¢˜ï¼ˆ| ä¹‹åï¼Œç¬¬äºŒä¸ª - ä¹‹å‰ï¼‰
                if '|' in full_title:
                    en_parts = full_title.split('|')
                    if len(en_parts) > 1:
                        en_part = en_parts[1].split('-')[0].strip()
                        if en_part:
                            en_title = en_part

                description = f"{en_title} - {cn_title}"
                print(f"  {number}: {cn_title} ({en_title}) [ä»HTML titleæå–]")

        # åˆ›å»ºé¡¹ç›®æ•°æ®
        project = {
            "number": number,
            "cn_title": cn_title,
            "en_title": en_title,
            "description": description,
            "url": f"projects/108 Cognitive Weapons/{filename}"
        }

        data.append(project)

    # ä¿å­˜ä¸ºJSONæ–‡ä»¶
    output_file = "data/cognitive-weapons.json"
    os.makedirs("data", exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… æˆåŠŸç”Ÿæˆ {len(data)} ä¸ªè®¤çŸ¥æ­¦å™¨æ•°æ®")
    print(f"ğŸ“„ ä¿å­˜åˆ°: {output_file}")

    return len(data)

if __name__ == "__main__":
    count = generate_cognitive_weapons_data()
    print(f"\næ€»è®¡: {count} ä¸ªè®¤çŸ¥æ­¦å™¨")
